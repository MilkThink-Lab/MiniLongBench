{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Perform representation learning for test samples\n",
    "\n",
    "In this notebook, we show how to learn the representation for test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from irt import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longbench': ['LongBench_2wikimqa',\n",
       "  'LongBench_dureader',\n",
       "  'LongBench_gov_report',\n",
       "  'LongBench_hotpotqa',\n",
       "  'LongBench_lcc',\n",
       "  'LongBench_lsht',\n",
       "  'LongBench_multifieldqa_en',\n",
       "  'LongBench_multifieldqa_zh',\n",
       "  'LongBench_multi_news',\n",
       "  'LongBench_musique',\n",
       "  'LongBench_narrativeqa',\n",
       "  'LongBench_passage_count',\n",
       "  'LongBench_passage_retrieval_en',\n",
       "  'LongBench_passage_retrieval_zh',\n",
       "  'LongBench_qasper',\n",
       "  'LongBench_qmsum',\n",
       "  'LongBench_repobench-p',\n",
       "  'LongBench_samsum',\n",
       "  'LongBench_trec',\n",
       "  'LongBench_triviaqa',\n",
       "  'LongBench_vcsum']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_handle_scenario = 'longbench'\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading longbench test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/longbench.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "names = np.array(data['models'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4750)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(scenarios, data)\n",
    "Y = create_responses(scenarios, data)\n",
    "# print(scenarios_position, subscenarios_position)\n",
    "\n",
    "    \n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "below you can see the scores for LongBench:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28705801919587143, ())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,scenarios_position[to_handle_scenario]], Y[:,scenarios_position[to_handle_scenario]].shape\n",
    "tmp = Y[:,scenarios_position[to_handle_scenario]]\n",
    "np.mean(tmp), np.mean(tmp).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Split the data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9874c5-7cb5-425b-8c41-9a87d7615ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4750) (20, 4750) (20, 4750)\n"
     ]
    }
   ],
   "source": [
    "train_idx = [32, 30, 25, 8, 0, 26, 7, 29, 12, 9, 23, 21, 1, 39, 6, 14, 11, 27, 20, 10]\n",
    "test_idx = [13, 34, 3, 38, 22, 24, 35, 37, 5, 4, 2, 19, 28, 33, 17, 18, 15, 36, 16, 31]\n",
    "\n",
    "Y_test = Y[test_idx]\n",
    "Y_train = Y[train_idx]\n",
    "\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85311989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 30, 25, 8, 0, 26, 7, 29, 12, 9, 23, 21, 1, 39, 6, 14, 11, 27, 20, 10] [13, 34, 3, 38, 22, 24, 35, 37, 5, 4, 2, 19, 28, 33, 17, 18, 15, 36, 16, 31]\n",
      "['ALMA-7B-Ja-V2' 'GOAT-7B-Community' 'Koss-7B-chat'\n",
      " 'Kunoichi-7BLlama-2-7b-chat-hf-10-sparsity' 'Llama-2-7b-ft-instruct-es'\n",
      " 'Mistral-7B-Instruct-v0.2-sparsity-20' 'OLMo-1B' 'airoboros-7b'\n",
      " 'gemma2-9b-hf' 'giraffe-7b' 'llama-2-7b-hf' 'llama-7b-hf'\n",
      " 'mistral-7b-v0.1-hf' 'perry-7b' 'qwen-7b-hf' 'qwen1.5-0.5b-hf'\n",
      " 'qwen2-0.5b-hf' 'qwen2.5-0.5b-base' 'qwen2.5-1.5b-base' 'tulu-7B-fp16']\n",
      "\n",
      "['Distilled-HermesChat-7B' 'Loyal-Macaroni-Maid-7B' 'OLMo-1B-SFT'\n",
      " 'StopCarbon-10.7B-v6' 'Synatra-RP-Orca-2-7b-v0.1' 'TowerInstruct-7B-v0.1'\n",
      " 'amd-llama-135m' 'amd-llama-135m-code' 'gemma2-2b-hf' 'llama-3-8b-hf'\n",
      " 'llama-30b' 'llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged'\n",
      " 'llama-shishya-7b-ep3-v1' 'manatee-7b' 'mistral-7b-v0.3-hf'\n",
      " 'qwen1.5-1.8b-hf' 'qwen2.5-0.5b-instruct-hf' 'qwen2.5-3b-base'\n",
      " 'qwen2.5-3b-instruct-hf' 'recycled-wizardlm-7b-v2.0']\n"
     ]
    }
   ],
   "source": [
    "print(train_idx, test_idx)\n",
    "names_train = np.sort(names[train_idx])\n",
    "names_test = np.sort(names[test_idx])\n",
    "print(names_train)\n",
    "print()\n",
    "print(names_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e856d5-3778-417f-b4e9-77cfc9f6e6a1",
   "metadata": {},
   "source": [
    "## Binarize all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739556a1-fd5c-4edb-8fd2-2e0914377eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1354.12it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_bin_train = np.zeros(Y_train.shape)\n",
    "Y_bin_test = np.zeros(Y_test.shape)\n",
    "\n",
    "cs = np.linspace(0.01,.99,100)  # Threshold values to consider\n",
    "for scenario in scenarios.keys():\n",
    "    ind = scenarios_position[scenario]\n",
    "    # Find the best threshold value that minimizes the difference between averages\n",
    "    c = cs[np.argmin([np.mean((np.abs((Y_train[:,ind]>c).mean(axis=1)-Y_train[:,ind].mean(axis=1)))) for c in tqdm(cs)])]\n",
    "    # Apply the threshold to train and test responses\n",
    "    Y_bin_train[:,ind] = (Y_train[:,ind]>c).astype(int)\n",
    "    Y_bin_test[:,ind] = (Y_test[:,ind]>c).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964dbee2-3607-4f6a-b287-29f12b5e20d5",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Obtain the OpenAI embeddings for the 4750 test cases of Longbench, and then reduce the dimensionality of the embeddings using PCA.\n",
    "\n",
    "Due to the large size of the embeddings, the full data cannot be uploaded. Only the results after PCA are provided here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4349a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4750, 1024)\n",
      "(4750, 10)\n"
     ]
    }
   ],
   "source": [
    "# with open(f'data\\\\longbench_embeddings.pkl', 'rb') as f:\n",
    "#     longbench_embeddings = pickle.load(f)\n",
    "# print(longbench_embeddings.shape)\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=10)\n",
    "# longbench_embeddings = pca.fit_transform(longbench_embeddings)\n",
    "# print(longbench_embeddings.shape)\n",
    "# with open(f'data\\\\longbench_embeddings_pca.pkl', 'wb') as f:\n",
    "#     pickle.dump(longbench_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840c3b1",
   "metadata": {},
   "source": [
    "## Representation learning\n",
    "\n",
    "To learn the representation for test samples, we use an adapted version of `py-irt` code\n",
    "\n",
    "The following models will read `data\\longbench_embeddings_pca.pkl` during initialization to set up the representations for test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9999beb9-9796-45ea-993b-cd293d343002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 4750) (1, 1, 4750) (20, 10, 1)\n",
      "[[[0.14152852 0.64271206 0.6490193  ... 0.70366305 0.92900026 0.70741272]]]\n"
     ]
    }
   ],
   "source": [
    "D = 10\n",
    "device = 'cuda' # Either 'cuda' or 'cpu' \n",
    "epochs = 2000  # Number of epochs for IRT model training \n",
    "lr = .1  # Learning rate for IRT model training \n",
    "\n",
    "\n",
    "# Saving the training dataset in the needed format\n",
    "create_irt_dataset(Y_bin_train, 'data/irt_dataset.jsonlines')\n",
    "\n",
    "\n",
    "train_irt_model(dataset_name='data/irt_dataset.jsonlines', \n",
    "                model_name='data/new_irt_model', \n",
    "                D=D, lr=lr, epochs=epochs, device=device)      \n",
    "A, B, Theta = load_irt_parameters('data/new_irt_model/')\n",
    "print(A.shape, B.shape, Theta.shape)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35926404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
