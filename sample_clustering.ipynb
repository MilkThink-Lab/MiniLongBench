{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# perform clustering to obtain the minilongbench\n",
    "\n",
    "In this notebook, we show how to cluster the representations to obtain the minilongbench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from irt import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longbench': ['LongBench_2wikimqa',\n",
       "  'LongBench_dureader',\n",
       "  'LongBench_gov_report',\n",
       "  'LongBench_hotpotqa',\n",
       "  'LongBench_lcc',\n",
       "  'LongBench_lsht',\n",
       "  'LongBench_multifieldqa_en',\n",
       "  'LongBench_multifieldqa_zh',\n",
       "  'LongBench_multi_news',\n",
       "  'LongBench_musique',\n",
       "  'LongBench_narrativeqa',\n",
       "  'LongBench_passage_count',\n",
       "  'LongBench_passage_retrieval_en',\n",
       "  'LongBench_passage_retrieval_zh',\n",
       "  'LongBench_qasper',\n",
       "  'LongBench_qmsum',\n",
       "  'LongBench_repobench-p',\n",
       "  'LongBench_samsum',\n",
       "  'LongBench_trec',\n",
       "  'LongBench_triviaqa',\n",
       "  'LongBench_vcsum']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_handle_scenario = 'longbench'\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading longbench data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/longbench.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4750)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(scenarios, data)\n",
    "Y = create_responses(scenarios, data)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f40fc53-b11e-41cc-adc2-7abff1a2b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_weights = np.ones(Y.shape[1])\n",
    "# per_scen indicates which scenario this document belongs to\n",
    "per_scen = [1, 1, 2, 1, 5, 3, 0, 0, 2, 1, 0, 4, 4, 4, 0, 2, 5, 3, 3, 3, 2]\n",
    "N = len(scenarios_position[to_handle_scenario])\n",
    "n_sub = len(scenarios[to_handle_scenario])\n",
    "for i, sub in enumerate(scenarios[to_handle_scenario]):\n",
    "    if per_scen[i] == 4:\n",
    "        num = 3\n",
    "    elif per_scen[i] == 5:\n",
    "        num = 2\n",
    "    else:\n",
    "        num = 4\n",
    "    n_i = len(subscenarios_position[to_handle_scenario][sub])\n",
    "    balance_weights[subscenarios_position[to_handle_scenario][sub]] = N/(num*6*n_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c94975",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f4bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# number_item = Y_train.shape[1]\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
    "\n",
    "scenario_dict = {\"Single-Document QA\":[\"LongBench_narrativeqa\", \"LongBench_qasper\", \"LongBench_multifieldqa_en\", \"LongBench_multifieldqa_zh\"],\n",
    "                \"Multi-Document QA\":[\"LongBench_hotpotqa\", \"LongBench_2wikimqa\", \"LongBench_musique\", \"LongBench_dureader\"],\n",
    "                \"Summarization\":[\"LongBench_gov_report\", \"LongBench_qmsum\", \"LongBench_vcsum\", \"LongBench_samsum\"],\n",
    "                \"Few-shot Learning\":[\"LongBench_trec\", \"LongBench_lsht\", \"LongBench_triviaqa\", \"LongBench_multi_news\"],\n",
    "                \"Code Completion\":[\"LongBench_lcc\", \"LongBench_repobench-p\"],\n",
    "                \"Synthetic Task\":[\"LongBench_passage_count\", \"LongBench_passage_retrieval_en\", \"LongBench_passage_retrieval_zh\"]}\n",
    "\n",
    "\n",
    "A, B, _ = load_irt_parameters('data/irt_model/')\n",
    "X = np.vstack((A.squeeze(), B.squeeze().reshape((1,-1)))).T\n",
    "# X = np.vstack((A.squeeze())).T\n",
    "X = X[scenarios_position['longbench']]\n",
    "norm_balance_weights = balance_weights[scenarios_position['longbench']]\n",
    "norm_balance_weights /= norm_balance_weights.sum()\n",
    "scenario = 'longbench'\n",
    "with open('data/sub_scenarios_pospos.pkl', 'rb') as f:\n",
    "    sub_scenarios_pospos = pickle.load(f)\n",
    "\n",
    "\n",
    "ratio = 0.95\n",
    "number_item = int((1-ratio) * 4750)\n",
    "\n",
    "clustering = 'irt' # 'correct.' or 'irt'\n",
    "\n",
    "anchor_points = {}\n",
    "anchor_weights = {}\n",
    "\n",
    "\n",
    "summ = 0\n",
    "for i in range(6):\n",
    "    idx = np.array(sub_scenarios_pospos[i])\n",
    "    if i == 5:\n",
    "        num = number_item - summ\n",
    "    else:\n",
    "        num = int(len(sub_scenarios_pospos[i]) / 4750 * number_item)\n",
    "    summ += num\n",
    "    # Fitting the KMeans model\n",
    "    kmeans = KMeans(n_clusters=num, n_init=\"auto\")\n",
    "    kmeans.fit(X[idx, :], sample_weight=norm_balance_weights[idx])\n",
    "    if i == 0:\n",
    "        # Calculating anchor points\n",
    "        tmp_points = pairwise_distances(kmeans.cluster_centers_, X[idx, :], metric='euclidean').argmin(axis=1)\n",
    "        anchor_points[scenario] = idx[tmp_points]\n",
    "        # Calculating anchor weights\n",
    "        anchor_weights[scenario] = np.array([np.sum(norm_balance_weights[idx][kmeans.labels_==c]) for c in range(num)])# * len(idx) / 4750 \n",
    "    else:\n",
    "        # Calculating anchor points\n",
    "        tmp_points = pairwise_distances(kmeans.cluster_centers_, X[idx, :], metric='euclidean').argmin(axis=1)\n",
    "        anchor_points[scenario] = np.concatenate((anchor_points[scenario], idx[tmp_points]))\n",
    "        # Calculating anchor weights\n",
    "        anchor_weights[scenario] = np.concatenate((anchor_weights[scenario], np.array([np.sum(norm_balance_weights[idx][kmeans.labels_==c]) for c in range(num)]) ))#* len(idx) / 4750)) \n",
    "\n",
    "with open(\"data/new_anchor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(anchor_points, f)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9458e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
